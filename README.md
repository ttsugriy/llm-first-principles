# Building LLMs from First Principles

A comprehensive educational resource teaching Large Language Model development from absolute first principles, with full mathematical derivations, performance-focused implementation, and systematic trade-off analysis.

**[Read Online â†’](https://ttsugriy.github.io/llm-first-principles/)**

**Author:** Taras Tsugrii | [Substack](https://softwarebits.substack.com/)

---

## Philosophy

> "Performance is the product of deep understanding of foundations."

Every formula is derived. Every algorithm is implemented from scratch. Every design decision is analyzed for performance trade-offs.

---

## Quick Start

### Read Online

Visit the [GitHub Pages site](https://ttsugriy.github.io/llm-first-principles/) for formatted content with proper math rendering.

### Build Locally

```bash
# Clone the repo
git clone https://github.com/ttsugriy/llm-first-principles.git
cd llm-first-principles

# Install jupyter-book
pip install jupyter-book

# Build the book
jupyter-book build .

# Open in browser
open _build/html/index.html
```

### Run Stage 1 Code

```bash
cd code/stage-01
python3 main.py
```

### Interactive Notebooks

Stage 1 includes a [marimo](https://marimo.io) interactive notebook:

```bash
pip install marimo numpy matplotlib
marimo run code/stage-01/stage_01_markov_interactive.py
```

---

## Repository Structure

```
llm-first-principles/
â”œâ”€â”€ _config.yml                     # Jupyter Book configuration
â”œâ”€â”€ _toc.yml                        # Table of contents
â”œâ”€â”€ intro.md                        # Book introduction
â”œâ”€â”€ stages/
â”‚   â”œâ”€â”€ stage-01/                   # Stage 1: Markov Chains
â”‚   â”‚   â”œâ”€â”€ index.md                # Stage overview
â”‚   â”‚   â”œâ”€â”€ 01-probability-foundations.md
â”‚   â”‚   â”œâ”€â”€ 02-language-modeling-problem.md
â”‚   â”‚   â”œâ”€â”€ 03-mle-derivation.md
â”‚   â”‚   â”œâ”€â”€ 04-information-theory.md
â”‚   â”‚   â”œâ”€â”€ 05-perplexity.md
â”‚   â”‚   â”œâ”€â”€ 06-temperature-sampling.md
â”‚   â”‚   â”œâ”€â”€ 07-implementation.md
â”‚   â”‚   â””â”€â”€ 08-trade-offs.md
â”‚   â””â”€â”€ stage-02-preview.md         # Coming soon
â”œâ”€â”€ code/
â”‚   â””â”€â”€ stage-01/                   # Stage 1 implementation
â”‚       â”œâ”€â”€ markov.py               # MarkovChain class
â”‚       â”œâ”€â”€ generate.py             # Text generation
â”‚       â”œâ”€â”€ evaluate.py             # Perplexity computation
â”‚       â””â”€â”€ main.py                 # Demo script
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ deploy-book.yml             # Auto-deploy to GitHub Pages
â””â”€â”€ planning/                       # Project planning docs
    â”œâ”€â”€ 00-PROJECT-OVERVIEW.md
    â”œâ”€â”€ 01-SPIRAL-STRUCTURE.md
    â””â”€â”€ ...
```

---

## Project Summary

### What This Is

A **first-principles approach** to teaching LLM development that:

1. **Derives all mathematics** from foundations (no "it's well known that...")
2. **Implements everything from scratch** (no magic libraries)
3. **Analyzes performance throughout** (every formula gets a FLOP count)
4. **Uses spiral learning** (concepts revisited with increasing depth)
5. **Follows PÃ³lya's problem-solving method** (understand â†’ plan â†’ execute â†’ reflect)
6. **Applies Tufte's design principles** (clear, honest, integrated presentation)

### Structure: 5 Spirals, 18 Stages

| Spiral | Theme | Stages | Focus |
|--------|-------|--------|-------|
| 1 | Foundations | 1-4 | Markov â†’ Neural LM |
| 2 | Training | 5-6 | Optimization, Stability |
| 3 | Transformer | 7-10 | Attention, Architecture |
| 4 | Making It Fast | 11-13 | Memory, Distributed |
| 5 | Modern Practice | 14-18 | Architectures, Alignment, Inference |

---

## Current Status

- âœ… Stage 1: Markov Chains (complete with 8 comprehensive sections)
- ðŸš§ Stage 2: Automatic Differentiation (coming soon)
- ðŸ“‹ Stages 3-18: Planned

---

## Contributing

Issues and PRs welcome! See the [GitHub repository](https://github.com/ttsugriy/llm-first-principles).

---

## License

Content: [TBD]
Code: MIT License

---

*Built with [Jupyter Book](https://jupyterbook.org)*
