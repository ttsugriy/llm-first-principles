<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Stage 1: Markov Chains | Building LLMs from First Principles</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}]});"></script>
    <style>
        :root {
            --bg: #fafafa;
            --text: #1a1a1a;
            --accent: #2563eb;
            --muted: #6b7280;
            --border: #e5e7eb;
            --code-bg: #f3f4f6;
        }

        @media (prefers-color-scheme: dark) {
            :root {
                --bg: #111827;
                --text: #f9fafb;
                --accent: #60a5fa;
                --muted: #9ca3af;
                --border: #374151;
                --code-bg: #1f2937;
            }
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
            line-height: 1.7;
            color: var(--text);
            background: var(--bg);
            padding: 2rem;
            max-width: 800px;
            margin: 0 auto;
        }

        nav {
            margin-bottom: 2rem;
            padding-bottom: 1rem;
            border-bottom: 1px solid var(--border);
        }

        nav a {
            color: var(--accent);
            text-decoration: none;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .meta {
            color: var(--muted);
            margin-bottom: 2rem;
        }

        h2 {
            font-size: 1.5rem;
            margin: 2.5rem 0 1rem;
            padding-top: 1rem;
            border-top: 1px solid var(--border);
        }

        h3 {
            font-size: 1.2rem;
            margin: 1.5rem 0 0.75rem;
        }

        p { margin-bottom: 1rem; }

        .callout {
            background: var(--code-bg);
            border-left: 4px solid var(--accent);
            padding: 1rem 1.25rem;
            margin: 1.5rem 0;
        }

        .callout-title {
            font-weight: 600;
            margin-bottom: 0.5rem;
        }

        pre {
            background: var(--code-bg);
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
            margin: 1rem 0;
            font-size: 0.9rem;
        }

        code {
            font-family: 'SF Mono', Consolas, monospace;
            font-size: 0.9em;
        }

        :not(pre) > code {
            background: var(--code-bg);
            padding: 0.15rem 0.4rem;
            border-radius: 3px;
        }

        ul, ol {
            margin: 1rem 0 1rem 1.5rem;
        }

        li { margin-bottom: 0.5rem; }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }

        th, td {
            border: 1px solid var(--border);
            padding: 0.5rem 0.75rem;
            text-align: left;
        }

        th {
            background: var(--code-bg);
            font-weight: 600;
        }

        .interactive-note {
            background: linear-gradient(135deg, #dbeafe 0%, #e0e7ff 100%);
            border: 1px solid #93c5fd;
            border-radius: 8px;
            padding: 1rem 1.25rem;
            margin: 1.5rem 0;
        }

        @media (prefers-color-scheme: dark) {
            .interactive-note {
                background: linear-gradient(135deg, #1e3a5f 0%, #312e81 100%);
                border-color: #3b82f6;
            }
        }

        .interactive-note a {
            color: var(--accent);
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            display: flex;
            justify-content: space-between;
        }

        footer a {
            color: var(--accent);
            text-decoration: none;
        }
    </style>
</head>
<body>
    <nav>
        <a href="../">‚Üê Building LLMs from First Principles</a>
    </nav>

    <header>
        <h1>Stage 1: The Simplest Language Model</h1>
        <p class="meta">Markov Chains ‚Äî Where It All Begins</p>
    </header>

    <main>
        <div class="interactive-note">
            <strong>üéÆ Interactive Version Available!</strong><br>
            <a href="../stage-01-interactive/">Launch the interactive notebook</a> ‚Äî adjust parameters with sliders, see live visualizations, and explore Markov chains hands-on in your browser.
        </div>

        <div class="callout">
            <div class="callout-title">üìñ Full Content Available</div>
            <p>
                The complete Stage 1 content with full derivations is available on GitHub:<br>
                <a href="https://github.com/ttsugriy/llm-first-principles/blob/main/stages/stage-01-complete.md" target="_blank">View Full Stage 1 Content (1800+ lines)</a>
            </p>
        </div>

        <h2>Overview</h2>
        <p>
            This stage builds a language model from absolute first principles. <strong>Every concept is derived.</strong>
            No "it's well known that..." hand-waving. By the end, you'll understand not just <em>what</em> language models do,
            but <em>why</em> they work mathematically.
        </p>

        <p><strong>Reading time:</strong> 60-90 minutes | <strong>Prerequisites:</strong> Basic Python, high school algebra</p>

        <h2>What You'll Learn</h2>

        <h3>Section 1.1: Probability Foundations</h3>
        <ul>
            <li>The three axioms of probability (Kolmogorov)</li>
            <li>Conditional probability derived from first principles</li>
            <li>The chain rule: full proof by induction</li>
            <li>Why this matters for language modeling</li>
        </ul>

        <h3>Section 1.2: The Language Modeling Problem</h3>
        <ul>
            <li>Formal definition of a language model</li>
            <li>Why the exponential space problem ($|V|^n$ sequences) is fundamental</li>
            <li>Autoregressive factorization using the chain rule</li>
            <li>The Markov assumption: why it helps and why it's wrong</li>
            <li>Quantitative analysis of context vs. vocabulary size</li>
        </ul>

        <h3>Section 1.3: Maximum Likelihood Estimation</h3>
        <ul>
            <li>What is a parameter? What is likelihood?</li>
            <li>Why logarithms: the log-likelihood trick</li>
            <li><strong>Full derivation:</strong> MLE for bigram models using Lagrange multipliers</li>
            <li>The beautiful result: counting = optimization (proven rigorously)</li>
            <li>Handling zero probabilities</li>
        </ul>

        <h3>Section 1.4: Information Theory</h3>
        <ul>
            <li>Deriving $I(p) = -\log p$ from axioms (surprise, additivity)</li>
            <li>Entropy: expected information</li>
            <li>Cross-entropy: using the wrong model</li>
            <li>KL divergence: the gap between distributions</li>
            <li>Why minimizing cross-entropy = maximizing likelihood</li>
        </ul>

        <h3>Section 1.5: Perplexity</h3>
        <ul>
            <li>Deriving perplexity from cross-entropy</li>
            <li>The "effective vocabulary size" interpretation (proven)</li>
            <li>Computing perplexity: worked examples</li>
            <li>Why perplexity is better than accuracy</li>
            <li>Train vs. test perplexity: detecting overfitting</li>
        </ul>

        <h3>Section 1.6: Temperature Sampling</h3>
        <ul>
            <li>Greedy decoding and its problems</li>
            <li>Ancestral sampling: the theoretically correct approach</li>
            <li>Temperature: derivation from softmax</li>
            <li>Connection to statistical mechanics (Boltzmann distribution)</li>
            <li>Limit behavior: $T \to 0$ (greedy), $T \to \infty$ (uniform)</li>
            <li>Top-k and nucleus sampling</li>
        </ul>

        <h3>Section 1.7: Implementation</h3>
        <ul>
            <li>Complete 150-line implementation with detailed annotations</li>
            <li>Every design decision explained (defaultdict, tuples, caching)</li>
            <li>Training, probability queries, generation, evaluation</li>
            <li>Time and space complexity analysis</li>
        </ul>

        <h3>Section 1.8: The Fundamental Trade-offs</h3>
        <ul>
            <li>The context-sparsity trade-off (with data)</li>
            <li>State space explosion: why it's unavoidable</li>
            <li>Long-range dependencies: examples of failure modes</li>
            <li>What carries forward to modern LLMs</li>
            <li>Preview: why neural networks solve these problems</li>
        </ul>

        <h2>Key Concepts</h2>

        <table>
            <tr><th>Concept</th><th>Formula</th><th>Intuition</th></tr>
            <tr>
                <td>Chain Rule</td>
                <td>$P(x_{1:n}) = \prod_i P(x_i | x_{&lt;i})$</td>
                <td>Factor into conditionals</td>
            </tr>
            <tr>
                <td>MLE</td>
                <td>$P(b|a) = \frac{\text{count}(a,b)}{\text{count}(a,\cdot)}$</td>
                <td>Counting is optimal</td>
            </tr>
            <tr>
                <td>Cross-entropy</td>
                <td>$H(P,Q) = -\mathbb{E}_P[\log Q]$</td>
                <td>Average surprise</td>
            </tr>
            <tr>
                <td>Perplexity</td>
                <td>$\exp(H)$</td>
                <td>Effective vocabulary</td>
            </tr>
            <tr>
                <td>Temperature</td>
                <td>$P'(x) \propto P(x)^{1/T}$</td>
                <td>Control randomness</td>
            </tr>
        </table>

        <h2>What Makes This Different</h2>

        <p>This isn't a "here's the formula" tutorial. Every claim is proven:</p>

        <ul>
            <li>‚úì Chain rule derived by induction, not stated</li>
            <li>‚úì MLE solution found using calculus (Lagrangian, full derivation)</li>
            <li>‚úì Information theory built from axioms</li>
            <li>‚úì Every code design choice explained</li>
            <li>‚úì Complexity analysis included</li>
        </ul>

        <div class="callout">
            <div class="callout-title">The Fundamental Trade-off</div>
            <p><strong>More context ‚Üí better predictions</strong><br>
            <strong>More context ‚Üí sparser observations</strong></p>
            <p>
                We prove this quantitatively and show experimental data. This limitation is why we need
                neural networks: they can <em>generalize</em> from similar patterns rather than requiring exact matches.
            </p>
        </div>

        <h2>What's Next?</h2>
        <p>
            We've built a working language model and proven its optimality. But it has fundamental limitations:
            no generalization, exponential state space, fixed context windows.
        </p>
        <p>
            To build models that generalize, we need to learn representations. That requires gradients.
            And computing gradients efficiently requires <strong>automatic differentiation</strong>.
        </p>
        <p>
            <strong>‚Üí Stage 2: Automatic Differentiation</strong> (Coming soon)
        </p>
    </main>

    <footer>
        <span><a href="../">‚Üê Home</a></span>
        <span>Stage 2: Coming Soon ‚Üí</span>
    </footer>
</body>
</html>
